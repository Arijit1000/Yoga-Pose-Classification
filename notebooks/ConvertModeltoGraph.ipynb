{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ConvertModeltoGraph.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"FdEaW3waO2iC","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install tflearn\n","!pip install pydrive\n","!pip install matplotlib\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wrxxOoC5M1Js","colab_type":"code","colab":{}},"cell_type":"code","source":["from __future__ import division, print_function, absolute_import\n","\n","import pickle\n","import time\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","\n","import tflearn\n","from tflearn.data_utils import shuffle, to_categorical\n","from tflearn.layers.core import input_data, dropout, fully_connected\n","from tflearn.layers.conv import conv_2d, max_pool_2d\n","from tflearn.layers.estimator import regression\n","from tflearn.data_preprocessing import ImagePreprocessing\n","from tflearn.data_augmentation import ImageAugmentation\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D8VAvezANFv1","colab_type":"code","colab":{}},"cell_type":"code","source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# 1. Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"g4qBoqVqNHu2","colab_type":"code","colab":{}},"cell_type":"code","source":["from pydrive.drive import GoogleDrive\n","\n","drive = GoogleDrive(gauth) # Create GoogleDrive instance with authenticated GoogleAuth instance\n","\n","# Auto-iterate through all files in the root folder.\n","file_list = drive.ListFile({'q': \"'1vQhQXjy4X9woILOTXeY3C-tz14xJkBQE' in parents and trashed=false\"}).GetList()\n","for file1 in file_list:\n","  if file1['title'] == 'test.pkl':\n","     TESTPIK = file1['id']\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5zKjUkX6fGAP","colab_type":"code","colab":{}},"cell_type":"code","source":["def gDriveAuthorization(auth_name,save_dir):\n","  auth.authenticate_user()\n","  gauth = GoogleAuth()\n","  # Try to load saved client credentials\n","  authcred_dir=save_dir+\"/\"+auth_name+\".txt\"\n","  \n","  if gauth.credentials is None:\n","      if os.path.isfile(authcred_dir):\n","        gauth.LoadCredentialsFile(authcred_dir)\n","      # Authenticate if they're not there\n","      gauth.credentials = GoogleCredentials.get_application_default()\n","      gauth.SaveCredentialsFile(authcred_dir)\n","  elif gauth.access_token_expired:\n","      # Refresh them if expired\n","      gauth.Refresh()\n","      gauth.SaveCredentialsFile(authcred_dir)\n","  else:\n","      # Initialize the saved creds\n","      gauth.Authorize()\n","  \n","  return GoogleDrive(gauth)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wlZjnBBYPGen","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","\n","label_pairs ={\n","    'adho_mukha_svanasana':1,\n","    'bharadvajasana':2,\n","    'pasasana':3,\n","    'salamba_sarvangasana':4,\n","    'salamba_sirsasana':5,\n","    'virabhadrasana_I':6,\n","    'virabhadrasana_II':7,\n","    'virabhadrasana_III':8\n","}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DiibTXnEMduW","colab_type":"code","colab":{}},"cell_type":"code","source":["from tensorflow.python.tools import freeze_graph\n","import os\n","import tensorflow as tf\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"A7f_n18LNTXn","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","from __future__ import division, print_function, absolute_import\n","\n","import tflearn\n","\n","# Residual blocks\n","# 32 layers: n=5, 56 layers: n=9, 110 layers: n=18\n","n = 5\n","\n","# Real-time data preprocessing\n","img_prep = tflearn.ImagePreprocessing()\n","#img_prep.add_featurewise_zero_center(per_channel=True)\n","\n","# Real-time data augmentation\n","img_aug = tflearn.ImageAugmentation()\n","#img_aug.add_random_flip_leftright()\n","#img_aug.add_random_blur()\n","#img_aug.add_random_crop([64, 64], padding=4)\n","\n","# Building Residual Network\n","network = tflearn.input_data(shape=[None, 64, 64, 3],\n","                         data_preprocessing=img_prep,\n","                         data_augmentation=img_aug)\n","network = tflearn.conv_2d(network, 16, 3, regularizer='L2', weight_decay=0.0001)\n","network = tflearn.residual_block(network, n, 16)\n","network = tflearn.residual_block(network, 1, 32, downsample=True)\n","network = tflearn.residual_block(network, n-1, 32)\n","network = tflearn.residual_block(network, 1, 64, downsample=True)\n","network = tflearn.residual_block(network, n-1, 64)\n","network = tflearn.batch_normalization(network)\n","network = tflearn.activation(network, 'relu')\n","network = tflearn.global_avg_pool(network)\n","# Regression\n","network = tflearn.fully_connected(network, 9, activation='softmax')\n","mom = tflearn.Momentum(0.1, lr_decay=0.1, decay_step=32000, staircase=True)\n","network = tflearn.regression(network,optimizer=mom,loss='categorical_crossentropy')\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"j5LgiTFiQBCL","colab_type":"code","colab":{}},"cell_type":"code","source":["drive=gDriveAuthorization(\"skeletal-insights-creds\",\".\")\n","model_name = \"resnet32_skeletal_insights\"\n","# Auto-iterate through all files in the root folder.\n","model_parentfolder_id=\"1Ay8W74_15gHTpEz-SARe-mxXBE-yTKoe\"\n","file_list = drive.ListFile({'q': \"'{parent_id}'\".format(parent_id=model_parentfolder_id) + \" in parents and trashed=false\"}).GetList()\n","for file1 in file_list:\n","  if file1['title'] == model_name :\n","   model_dir = drive.ListFile({'q': \"'{folderid}' in parents and trashed=false\".format(folderid=file1['id'])}).GetList()\n","for file1 in file_list:\n","   for file2 in model_dir:\n","      drive.CreateFile({'id': file2['id']}).GetContentFile(file2['title']) "],"execution_count":0,"outputs":[]},{"metadata":{"id":"INa2LvyRTl20","colab_type":"code","colab":{}},"cell_type":"code","source":["def authenticateWithGDrive():\n","  auth.authenticate_user()\n","  gauth = GoogleAuth()\n","  gauth.credentials = GoogleCredentials.get_application_default()\n","  return GoogleDrive(gauth)\n","#Recursive function to walk through google drive repo        \n","def retrieveFolderfromGoogleDrive(parentfolder_id,targetdir='.') :\n","  drive=authenticateWithGDrive()\n","  file_list = drive.ListFile({'q': \"'{parent_id}'\".format(parent_id=parentfolder_id) + \" in parents and trashed=false\"}).GetList()\n","  for file1 in file_list:\n","    #print(file1['title'] +'__'+file1['mimeType'])\n","    sub_dir1=targetdir+'/'+file1['title']\n","    #if folder call same function\n","    if '.git' not in file1['title'] :\n","      if file1['mimeType'] == \"application/vnd.google-apps.folder\":\n","          if not os.path.isdir(sub_dir1):\n","            !mkdir {sub_dir1}\n","          retrieveFolderfromGoogleDrive(file1['id'],sub_dir1)\n","      else  :\n","        if not os.path.isfile(sub_dir1):\n","          drive.CreateFile({'id': file1['id']}).GetContentFile(sub_dir1)\n","dependencies_folder_id='19tYr3vwQsxc3l6HQLvfIgSK5gfr23soR'\n","retrieveFolderfromGoogleDrive(dependencies_folder_id)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_sKamg9cOb-S","colab_type":"code","colab":{}},"cell_type":"code","source":["model = tflearn.DNN(network)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dodXK8SzWLKf","colab_type":"code","colab":{}},"cell_type":"code","source":["model.load(model_name)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SCN9nSOd0ip4","colab_type":"code","colab":{}},"cell_type":"code","source":["del tf.get_collection_ref(tf.GraphKeys.TRAIN_OPS)[:]\n","model.save(model_name)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"a-u0oQDMUHiF","colab_type":"code","colab":{}},"cell_type":"code","source":["import os, argparse\n","\n","# The original freeze_graph function\n","# from tensorflow.python.tools.freeze_graph import freeze_graph \n","\n","# dir = os.path.dirname(os.path.realpath(__file__))\n","\n","def freeze_graph(model_dir, output_node_names):\n","    \"\"\"Extract the sub graph defined by the output nodes and convert \n","    all its variables into constant \n","    Args:\n","        model_dir: the root folder containing the checkpoint state file\n","        output_node_names: a string, containing all the output node's names, \n","                            comma separated\n","    \"\"\"\n","    if not tf.gfile.Exists(model_dir):\n","        raise AssertionError(\n","            \"Export directory doesn't exists. Please specify an export \"\n","            \"directory: %s\" % model_dir)\n","\n","    if not output_node_names:\n","        print(\"You need to supply the name of a node to --output_node_names.\")\n","        return -1\n","\n","    # We retrieve our checkpoint fullpath\n","    checkpoint = tf.train.get_checkpoint_state(model_dir)\n","    input_checkpoint = checkpoint.model_checkpoint_path\n","    \n","    # We precise the file fullname of our freezed graph\n","    absolute_model_dir = \"/\".join(input_checkpoint.split('/')[:-1])\n","    output_graph = absolute_model_dir + \"/frozen_model.pb\"\n","\n","    # We clear devices to allow TensorFlow to control on which device it will load operations\n","    clear_devices = True\n","\n","    # We start a session using a temporary fresh Graph\n","    with tf.Session(graph=tf.Graph()) as sess:\n","        # We import the meta graph in the current default Graph\n","        saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)\n","\n","        # We restore the weights\n","        saver.restore(sess, input_checkpoint)\n","        \n","        # get graph definition\n","        gd = sess.graph.as_graph_def()\n","\n","        # fix batch norm nodes\n","        for node in gd.node:\n","          if node.op == 'RefSwitch':\n","            node.op = 'Switch'\n","            for index in range(len(node.input)):\n","              if 'moving_' in node.input[index]:\n","                node.input[index] = node.input[index] + '/read'\n","          elif node.op == 'AssignSub':\n","            node.op = 'Sub'\n","            if 'use_locking' in node.attr: del node.attr['use_locking']\n","          \n","          if 'dilations' in node.attr:\n","            del node.attr['dilations'] \n","            \n","        #Remove attr\n","\n","        # We use a built-in TF helper to export variables to constants\n","        output_graph_def = tf.graph_util.convert_variables_to_constants(\n","            sess, # The session is used to retrieve the weights\n","            gd, # The graph_def is used to retrieve the nodes \n","            output_node_names.split(\",\") # The output node names are used to select the usefull nodes\n","        ) \n","\n","        # Finally we serialize and dump the output graph to the filesystem\n","        with tf.gfile.GFile(output_graph, \"wb\") as f:\n","            f.write(output_graph_def.SerializeToString())\n","        print(\"%d ops in the final graph.\" % len(output_graph_def.node))\n","\n","    return output_graph_def\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IoZTrnlztBNj","colab_type":"code","colab":{}},"cell_type":"code","source":["from tensorflow.python.tools import strip_unused_lib\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"88ZpQ3cqUKYH","colab_type":"code","colab":{}},"cell_type":"code","source":["freeze_graph('.',\"FullyConnected/Softmax\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"beGl_ApOOAx0","colab_type":"code","colab":{}},"cell_type":"code","source":["!cp frozen_model.pb $model_name'.pb'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tPUIIo6dNYZQ","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"kxYnPBJ4N_uS","colab_type":"code","colab":{}},"cell_type":"code","source":["!rm resnet32_skeletal_insights.py"],"execution_count":0,"outputs":[]},{"metadata":{"id":"L1LFEVQl4w4S","colab_type":"code","colab":{}},"cell_type":"code","source":["model_folder_id='1Ay8W74_15gHTpEz-SARe-mxXBE-yTKoe'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"A864_PG2enKT","colab_type":"code","colab":{}},"cell_type":"code","source":["def uploadFileToGoogleDrive(local_file_dir,name,parentfolder_id):\n","  drive=gDriveAuthorization(\"skeletal-insights-creds\",\".\")\n","  file=drive.CreateFile({'title': name,'parents':[{\"kind\": \"drive#fileLink\", \"id\": parentfolder_id}]})\n","  file.SetContentFile(local_file_dir)\n","  file.Upload()\n","  return file.get('id')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"819bF9Iq4-1r","colab_type":"code","colab":{}},"cell_type":"code","source":["uploadFileToGoogleDrive(model_name+\".pb\",model_name+\".pb\",model_folder_id)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cJBIv6z5MQff","colab_type":"code","colab":{}},"cell_type":"code","source":["from pydrive.drive import GoogleDrive\n","\n","drive = GoogleDrive(gauth) # Create GoogleDrive instance with authenticated GoogleAuth instance\n","\n","# Auto-iterate through all files in the root folder.\n","file_list = drive.ListFile({'q': \"'1vQhQXjy4X9woILOTXeY3C-tz14xJkBQE' in parents and trashed=false\"}).GetList()\n","for file1 in file_list:\n","  if file1['title'] == 'train.pkl':\n","     PIK = file1['id']\n","     print('title: %s, id: %s' % (file1['title'], file1['id']))\n","  elif file1['title'] == 'validation.pkl':\n","     VALIDPIK = file1['id']\n","     print('title: %s, id: %s' % (file1['title'], file1['id']))\n","  elif file1['title'] == 'test.pkl':\n","     TESTPIK = file1['id']\n","     print('title: %s, id: %s' % (file1['title'], file1['id']))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"74RQ9KtVMYCE","colab_type":"code","colab":{}},"cell_type":"code","source":["testFile = drive.CreateFile({'id': TESTPIK}).GetContentFile('test.pkl')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gmLEDVSfMUff","colab_type":"code","colab":{}},"cell_type":"code","source":["X = []\n","Y = []\n","X_validate = []\n","Y_validate = []\n","X_test = []\n","Y_test = []\n","\n","label_pairs ={\n","    'adho_mukha_svanasana':1,\n","    'bharadvajasana':2,\n","    'pasasana':3,\n","    'salamba_sarvangasana':4,\n","    'salamba_sirsasana':5,\n","    'virabhadrasana_I':6,\n","    'virabhadrasana_II':7,\n","    'virabhadrasana_III':8\n","}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bzq51krKMce2","colab_type":"code","colab":{}},"cell_type":"code","source":["X_type = 'float64'\n","\n","with open('test.pkl', \"rb\") as f:\n","    while True :\n","        try:\n","            record=pickle.load(f)\n","            X_test.append(record[0].astype(X_type))\n","            Y_test.append(label_pairs[record[1]])\n","        except EOFError:\n","            print('processing done!')\n","            break\n","            \n","print (\"Test Data Size :\" , len(X_test))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"905hk4r3u0J_","colab_type":"code","colab":{}},"cell_type":"code","source":["def getActivations(layer,stimuli,model):\n","    sess=model.session\n","    units = sess.run(layer,feed_dict={x:np.reshape(stimuli,[1,784],order='F'),keep_prob:1.0})\n","    plotNNFilter(units)\n","    \n","def plotNNFilter(units):\n","    filters = units.shape[3]\n","    plt.figure(1, figsize=(20,20))\n","    n_columns = 6\n","    n_rows = math.ceil(filters / n_columns) + 1\n","    for i in range(filters):\n","        plt.subplot(n_rows, n_columns, i+1)\n","        plt.title('Filter ' + str(i))\n","        plt.imshow(units[0,:,:,i], interpolation=\"nearest\", cmap=\"gray\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sxTaZDa1GjRL","colab_type":"code","colab":{}},"cell_type":"code","source":["layer=tflearn.variables.get_layer_variables_by_name(\"GlobalAvgPool\")\n","getActivations(layer,X_test[0],model)"],"execution_count":0,"outputs":[]}]}